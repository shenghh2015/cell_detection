{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imposed-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from natsort import natsorted\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "trying-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(file_name):\n",
    "    with open(file_name, 'r+') as f:\n",
    "        fns = [line.strip() for line in f.readlines()]\n",
    "        return fns\n",
    "\n",
    "def generate_folder(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.system('mkdir -p {}'.format(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continuous-joshua",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "The 0-th image processed!\n"
     ]
    }
   ],
   "source": [
    "''' prepare the bounding box annotations for 5 types of cells(docker version)\n",
    "'''\n",
    "label_map = {1:\"neutrophils\",\n",
    "            2:\"bands\",\n",
    "            3:\"eosinophils\",\n",
    "            4:\"lymphocytes\",\n",
    "            5:\"monocytes\"}\n",
    "\n",
    "# subset = 'train'\n",
    "# subset = 'valid'\n",
    "subset = 'test'\n",
    "areas = []\n",
    "dataset_dir = '/home/sh38/wb_cells/datasets/wbc_1024x1024'\n",
    "dataset_dir2 = '/data/datasets/wbc_1024x1024'\n",
    "output_dir = 'wbc_docker'  # the folder that save the output file\n",
    "fn_set = read_lines(dataset_dir + '/{}_list.txt'.format(subset))\n",
    "fns = os.listdir(dataset_dir + '/rcnn/data')\n",
    "print(len(fn_set))\n",
    "generate_folder(output_dir)\n",
    "file_name = '{}/{}_5c.csv'.format(output_dir, subset)\n",
    "with open(file_name, 'w+') as f:\n",
    "    for i, fn in enumerate(fns):\n",
    "        if not fn in fn_set:\n",
    "            continue\n",
    "        mask_dir = dataset_dir + '/rcnn/data/' + fn + '/masks'\n",
    "        mask_fns = os.listdir(mask_dir)\n",
    "        for mfn in mask_fns:\n",
    "            mask_file = os.path.join(mask_dir, mfn)\n",
    "            mask = io.imread(mask_file)\n",
    "            cls = np.unique(mask)[-1]\n",
    "            label = label_map[cls]\n",
    "            ys, xs = np.where(mask > 0)\n",
    "            areas.append(len(ys))\n",
    "            if len(ys) < 100:\n",
    "                continue\n",
    "            # skip the band category\n",
    "            #if cls == 2:\n",
    "            #    continue\n",
    "            f.write('{},{},{},{},{},{}\\n'.format(dataset_dir2 + '/images/{}.png'.format(fn),\\\n",
    "                    min(xs), min(ys), max(xs), max(ys), label_map[cls]))\n",
    "        if i % 100 == 0:\n",
    "            print('The {}-th image processed!'.format(i))\n",
    "\n",
    "with open(output_dir + '/class_5c.csv', 'w+') as f:\n",
    "    for key in label_map.keys():\n",
    "        f.write('{},{}\\n'.format(label_map[key], key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "seasonal-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' generate the train/val/test file for the wbc datasets for docker\n",
    "'''\n",
    "# subset = 'train'\n",
    "# subset = 'valid'\n",
    "subset = 'test'\n",
    "dataset = 'wbc2'\n",
    "file_name = 'wbc_docker/{}_5c.csv'.format(subset)\n",
    "output_dir = '{}_docker'.format(dataset)\n",
    "generate_folder(output_dir)\n",
    "output_file = output_dir + '/{}_5c.csv'.format(subset)\n",
    "with open(file_name, 'r+') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(output_file, 'w+') as f:\n",
    "    for line in lines:\n",
    "        f.write(line.replace('wbc_1024x1024', '{}_1024x1024'.format(dataset)))\n",
    "\n",
    "with open(output_dir + '/class_5c.csv', 'w+') as f:\n",
    "    for key in label_map.keys():\n",
    "        f.write('{},{}\\n'.format(label_map[key], key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "realistic-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' generate the train/val/test file for the wbc datasets for docker\n",
    "'''\n",
    "# subset = 'train'\n",
    "# subset = 'valid'\n",
    "subset = 'test'\n",
    "dataset = 'wbc3'\n",
    "file_name = 'wbc_docker/{}_5c.csv'.format(subset)\n",
    "output_dir = '{}_docker'.format(dataset)\n",
    "generate_folder(output_dir)\n",
    "output_file = output_dir + '/{}_5c.csv'.format(subset)\n",
    "with open(file_name, 'r+') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(output_file, 'w+') as f:\n",
    "    for line in lines:\n",
    "        f.write(line.replace('wbc_1024x1024', '{}_1024x1024'.format(dataset)))\n",
    "\n",
    "with open(output_dir + '/class_5c.csv', 'w+') as f:\n",
    "    for key in label_map.keys():\n",
    "        f.write('{},{}\\n'.format(label_map[key], key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-binding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
